# embedding_client.py
import os
import logging
import numpy as np
from typing import List

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

logger = logging.getLogger(__name__)

# ==============================
# å…¨å±€ç¼“å­˜å˜é‡ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
# ==============================
_LOCAL_EMBEDDING_MODEL = None
_DASHSCOPE_CONFIGURED = False


def _get_local_model():
    global _LOCAL_EMBEDDING_MODEL
    if _LOCAL_EMBEDDING_MODEL is None:
        logger.info("ðŸ”„ é¦–æ¬¡åŠ è½½æœ¬åœ° MiniLM æ¨¡åž‹ï¼ˆ384 ç»´ï¼‰...")
        try:
            from sentence_transformers import SentenceTransformer
            import torch
            device = "cuda" if torch.cuda.is_available() else "cpu"
            _LOCAL_EMBEDDING_MODEL = SentenceTransformer(
                "paraphrase-multilingual-MiniLM-L12-v2",
                device=device
            )
            logger.info(f"âœ… MiniLM æ¨¡åž‹åŠ è½½å®Œæˆï¼ˆè®¾å¤‡: {device}ï¼‰")
        except Exception as e:
            raise RuntimeError(f"åŠ è½½ MiniLM å¤±è´¥: {e}")
    return _LOCAL_EMBEDDING_MODEL


def get_local_embeddings(texts: List[str]) -> np.ndarray:
    model = _get_local_model()  # å¤ç”¨å·²åŠ è½½æ¨¡åž‹
    embeddings = model.encode(
        texts,
        show_progress_bar=False,
        convert_to_numpy=True,
        normalize_embeddings=True
    ).astype(np.float32)
    return embeddings


def get_qwen_embeddings(texts: List[str]) -> np.ndarray:
    global _DASHSCOPE_CONFIGURED
    try:
        import dashscope
        from dashscope import TextEmbedding
    except ImportError:
        raise ImportError("è¯·å®‰è£…: pip install dashscope")

    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("âŒ æœªè®¾ç½® DASHSCOPE_API_KEY")

    if not _DASHSCOPE_CONFIGURED:
        dashscope.api_key = api_key
        _DASHSCOPE_CONFIGURED = True
        logger.info("â˜ï¸ Qwen Embedding å·²é…ç½®ï¼ˆAPI Key è®¾ç½®æˆåŠŸï¼‰")

    embeddings = []
    batch_size = 25
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        response = TextEmbedding.call(
            model="text-embedding-v2",
            input=batch
        )
        if response.status_code != 200:
            raise RuntimeError(f"Qwen API é”™è¯¯: {response.code} - {response.message}")
        embeddings.extend([item["embedding"] for item in response.output["embeddings"]])
    
    return np.array(embeddings, dtype=np.float32)


def get_embeddings(texts: List[str]) -> np.ndarray:
    use_qwen = os.getenv("USE_QWEN_EMBEDDING", "false").lower() == "true"
    if use_qwen:
        return get_qwen_embeddings(texts)
    else:
        return get_local_embeddings(texts)